# AI机械臂项目代码分析文档

## 项目概述

这是一个基于AI的机械臂控制项目，实现了"能看懂图像、听懂人话、指哪打哪"的智能机械臂功能。项目集成了大语言模型、多模态视觉识别、语音交互等技术，使机械臂能够理解自然语言指令，通过视觉识别环境中的物体，并执行相应的操作。

## 文件结构总览

```
agent_demo_20250328/
├── asset/                    # 资源文件目录
│   ├── SimHei.ttf            # 中文字体文件
│   └── welcome.wav           # 欢迎音频
├── temp/                     # 临时文件目录
│   ├── record.txt            # 拖动示教录制数据
│   ├── speech_record.wav     # 语音识别录音
│   ├── tts.wav               # 语音合成输出
│   ├── vl_now.jpg            # 摄像头拍摄原图
│   └── vl_now_viz.jpg        # 视觉识别可视化结果
├── visualizations/           # 视觉识别结果存档
├── API_KEY.py                # API密钥配置
├── README.ipynb              # 项目说明文档
├── agent_go.py               # 主程序入口
├── camera_check.py           # 摄像头检查工具
├── sound_check.py            # 声音检查工具
├── utils_agent.py            # 智能体Agent编排
├── utils_asr.py              # 录音+语音识别
├── utils_camera.py           # 摄像头控制
├── utils_drag_teaching.py    # 拖动示教功能
├── utils_led.py              # LED灯颜色控制
├── utils_llm.py              # 大语言模型API调用
├── utils_pump.py             # 吸泵控制
├── utils_robot.py            # 机械臂运动控制
├── utils_tts.py              # 语音合成
├── utils_vlm.py              # 多模态视觉大模型
└── utils_vlm_move.py         # 多模态控制移动物体
```

## 核心文件功能介绍

### 1. 主程序入口

#### agent_go.py
- **功能**：项目的主程序入口，负责整合各模块功能，实现智能体的整体编排
- **主要流程**：
  1. 初始化各功能模块
  2. 播放欢迎音频
  3. 接收用户指令（语音输入或键盘输入）
  4. 调用智能体编排模块解析指令并生成动作序列
  5. 执行动作序列并反馈执行结果
  6. 支持循环交互

### 2. 智能体与语言处理

#### utils_agent.py
- **功能**：实现智能体的核心逻辑，负责将用户自然语言指令转换为机械臂可执行的动作序列
- **核心组件**：
  - 系统提示词（AGENT_SYS_PROMPT）：定义智能体的行为模式和可用功能
  - agent_plan()：调用大语言模型解析用户指令，生成JSON格式的动作序列

#### utils_llm.py
- **功能**：封装大语言模型API调用
- **支持的模型**：
  - 百度智能云千帆大模型（ERNIE-Bot-4等）
  - 零一万物大模型（yi-large等）
- **主要函数**：
  - llm_qianfan()：调用百度千帆大模型API
  - llm_yi()：调用零一万物大模型API

#### utils_asr.py
- **功能**：实现语音录制和语音识别功能
- **主要函数**：
  - record()：录制指定时长的音频
  - record_auto()：支持音量触发的自动录音
  - speech_recognition()：调用语音识别API将音频转换为文本

#### utils_tts.py
- **功能**：实现文本到语音的转换
- **主要函数**：
  - tts()：将文本转换为wav音频文件
  - play_wav()：播放wav音频文件

### 3. 视觉识别与处理

#### utils_vlm.py
- **功能**：封装多模态视觉大模型API调用，实现图像内容理解
- **支持的模型**：
  - Yi-Vision（零一万物）
  - QwenVL（通义千问）
- **主要函数**：
  - yi_vision_api()：调用Yi-Vision多模态API
  - QwenVL_api()：调用QwenVL多模态API
  - post_processing_viz()：视觉识别结果的后处理和可视化

#### utils_vlm_move.py
- **功能**：实现基于视觉识别的物体抓取和移动
- **主要流程**：
  1. 接收用户指令
  2. 控制机械臂移动到俯视姿态
  3. 拍摄当前场景图片
  4. 调用多模态大模型识别目标物体位置
  5. 计算目标物体的机械臂坐标
  6. 控制机械臂执行抓取和移动操作

#### utils_camera.py
- **功能**：实现摄像头的基本控制功能
- **主要函数**：
  - check_camera()：开启摄像头并实时显示画面

### 4. 机械臂控制

#### utils_robot.py
- **功能**：实现机械臂的连接和基本运动控制
- **主要函数**：
  - back_zero()：机械臂归零
  - relax_arms()：放松机械臂关节
  - head_shake()/head_nod()/head_dance()：预设动作
  - move_to_coords()：移动到指定坐标
  - single_joint_move()：单个关节运动
  - move_to_top_view()：移动到俯视姿态
  - top_view_shot()：拍摄俯视图
  - eye2hand()：手眼标定坐标转换
  - pump_move()：吸泵移动物体

#### utils_pump.py
- **功能**：实现吸泵的控制功能
- **主要函数**：
  - pump_on()：开启吸泵
  - pump_off()：关闭吸泵并泄气

#### utils_drag_teaching.py
- **功能**：实现拖动示教功能，允许用户手动拖动机械臂记录动作并回放
- **主要功能**：
  - 录制机械臂运动轨迹
  - 回放录制的动作
  - 循环回放功能
  - 保存和加载录制数据

#### utils_led.py
- **功能**：控制机械臂上LED灯的颜色
- **主要函数**：
  - llm_led()：通过大语言模型解析颜色描述并设置LED灯颜色

## 模块调用关系图

```
┌────────────────┐
│  agent_go.py   │──┬─►┌─────────────────┐
└────────────────┘  │  │  utils_agent.py │──►┌──────────────┐
                    │  └─────────────────┘   │ utils_llm.py │
                    │                        └──────────────┘
                    │  ┌─────────────────┐
                    ├─►│  utils_asr.py   │
                    │  └─────────────────┘
                    │  ┌─────────────────┐   ┌───────────────┐
                    ├─►│ utils_robot.py  │──►│ utils_pump.py │
                    │  └─────────────────┘   └───────────────┘
                    │  ┌─────────────────┐   ┌──────────────────┐
                    ├─►│ utils_tts.py    │   │ API_KEY.py       │
                    │  └─────────────────┘   └──────────────────┘
                    │  ┌─────────────────┐   ┌──────────────────┐   ┌─────────────────┐
                    ├─►│utils_vlm_move.py│──►│  utils_vlm.py    │──►│utils_camera.py  │
                    │  └─────────────────┘   └──────────────────┘   └─────────────────┘
                    │  ┌─────────────────┐
                    └─►│utils_drag_teach.py│
                       └─────────────────┘
```

## 代码执行流程

### 1. 系统启动流程

1. 运行`agent_go.py`作为程序入口
2. 初始化各功能模块和硬件连接（机械臂、摄像头、GPIO等）
3. 播放欢迎音频
4. 机械臂归零

### 2. 用户交互与指令处理

1. 用户通过语音或键盘输入指令
2. 语音输入：通过`utils_asr.py`进行录音和语音识别
3. 键盘输入：直接接收文本指令
4. 调用`utils_agent.py`中的智能体编排模块解析指令
5. 大语言模型生成JSON格式的动作序列

### 3. 动作执行流程

1. 解析动作序列中的函数调用
2. 按顺序执行各个功能函数：
   - 机械臂运动：`utils_robot.py`中的相关函数
   - 视觉识别：`utils_vlm.py`和`utils_vlm_move.py`
   - 吸泵控制：`utils_pump.py`
   - LED灯控制：`utils_led.py`
   - 拖动示教：`utils_drag_teaching.py`
3. 执行过程中提供实时反馈

### 4. 视觉引导运动流程

1. 接收到包含物体操作的指令（如"把绿色方块放在篮球上"）
2. 机械臂移动到俯视姿态
3. 拍摄当前场景图片
4. 调用多模态大模型识别目标物体位置
5. 进行手眼标定坐标转换
6. 控制机械臂执行抓取和移动操作
7. 保存视觉识别结果到`visualizations/`目录

## 自定义机械臂需要修改的部分

### 1. 机械臂连接与控制

- **文件**：`utils_robot.py`
- **需要修改的部分**：
  - 机械臂连接配置：
    ```python
    # 连接机械臂
    mc = MyCobot(PI_PORT, PI_BAUD)
    ```
  - 根据不同机械臂的控制协议修改相关函数
  - 机械臂关节数量和角度范围
  - 运动速度参数
  - 坐标系统定义

### 2. 硬件接口

- **文件**：`utils_pump.py`、`utils_robot.py`
- **需要修改的部分**：
  - GPIO引脚配置：
    ```python
    # 初始化GPIO
    GPIO.setup(20, GPIO.OUT)  # 吸泵电磁阀
    GPIO.setup(21, GPIO.OUT)  # 泄气流阀
    ```
  - 吸泵控制逻辑
  - 电压和电流参数（根据实际硬件）

### 3. 手眼标定

- **文件**：`utils_robot.py`
- **需要修改的部分**：
  - 手眼标定参数：
    ```python
    # 整理两个标定点的坐标
    cali_1_im = [130, 290]  # 左下角，第一个标定点的像素坐标
    cali_1_mc = [-21.8, -197.4]  # 左下角，第一个标定点的机械臂坐标
    cali_2_im = [640, 0]  # 右上角，第二个标定点的像素坐标
    cali_2_mc = [215, -59.1]  # 右上角，第二个标定点的机械臂坐标
    ```
  - 根据新的摄像头和机械臂配置重新进行手眼标定

### 4. 预设动作

- **文件**：`utils_robot.py`
- **需要修改的部分**：
  - 摇头、点头、跳舞等预设动作的角度参数
    ```python
    def head_shake():
        # 左右摆头
        mc.send_angles([0.87,(-50.44),47.28,0.35,(-0.43),(-0.26)],70)
        time.sleep(1)
        # ...
    ```
  - 根据机械臂的实际运动范围调整角度参数

### 5. 视觉识别参数

- **文件**：`utils_vlm.py`
- **需要修改的部分**：
  - 图像缩放因子：
    ```python
    # 缩放因子
    FACTOR = 999
    ```
  - 根据摄像头分辨率调整坐标转换逻辑
  - 可视化参数

### 6. API密钥与服务配置

- **文件**：`API_KEY.py`
- **需要修改的部分**：
  - 大语言模型API密钥
  - 语音识别、语音合成API密钥
  - API服务地址配置

### 7. 硬件驱动与依赖

- **需要修改的部分**：
  - 根据新的硬件平台安装相应的驱动
  - 修改Python依赖库
  - 调整操作系统相关命令（如音频播放、摄像头控制）

## 总结

该项目提供了一个完整的AI机械臂控制框架，集成了多模态交互和智能决策功能。要将其应用于自定义机械臂，主要需要修改机械臂连接协议、硬件接口配置、手眼标定参数和预设动作等部分。通过这些修改，可以使项目适配不同类型和品牌的机械臂，实现个性化的智能控制功能。